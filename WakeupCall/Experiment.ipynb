{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação de redes neurais - Visão computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pela Lei Brasileira e segurança no transito é proibido dirigir sonolento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting numpy>=1.21.2 (from opencv-python)\n",
      "  Using cached numpy-2.1.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Using cached numpy-2.1.2-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Installing collected packages: numpy, opencv-python\n",
      "Successfully installed numpy-2.1.2 opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# while cap.isOpened() - enquanto a camera estiver aberta o while continuara rodando\n",
    "while cap.isOpened():\n",
    "    # vamos criar duas variáveis\n",
    "    \n",
    "    # SUCESSO verifica se os dados estão sendo coletados.\n",
    "            #  Ela é booleana, significa que se identificar algum vídeo ou frame, retornará verdadeiro. Se não identificar nenhum vídeo, retornará falso\n",
    "    # FRAME é uma variável frame que por sua vez, é a captura coletada pela câmera. \n",
    "\n",
    "    sucesso,frame = cap.read()  # Utilizaremos o método cap.read() para leitura\n",
    "    # agora vamos usar o if (condicional), vamos verificar se existe ou não captura acontecendo\n",
    "    # se não tivermos sucesso (booleano), queremos uma mensagem na tela - ignorando o frame vazio da camêra\n",
    "    # essa mensagem é um aviso, logo , nada esta acontecendo no nosso projeto\n",
    "    if not sucesso:\n",
    "        print('Ignorando o frame vazio da camêra')\n",
    "        continue # pesquise sobre a diferença do continue e break (história go to)\n",
    "    # depois disso, saímos do bloco condicional e podemos visualizar a captura e conferir o que está acontecendo.\n",
    "    # podemos contar com o método imshow( ) pra isso\n",
    "    # dentro dos parenteses passamos dois parâmetros 'Camera' e frame\n",
    "    # Passaremos um nome para nossa janela no formato string 'Camera'\n",
    "    # Também outro parametro - frame - definindo que o que queremos mostrar que é nosso próprio frame\n",
    "    cv2.imshow('Camera',frame)\n",
    "    # com isso, conseguiremos mostrar a imagem, mas não temos uma opção de controle para fechar a camera em tempo real.\n",
    "    # Para isso, usaremos um condicional if\n",
    "    # Ele vai pegar o laço de repetição quando apertarmos teclas específicas.\n",
    "    # Como a intenção é fechar vamos usar \"C\" de \"Close\"\n",
    "    # waitKey(10) vai esperar uma chave\n",
    "    # verificar se essa chave é c\n",
    "    # Para isso passamos & OxFF \n",
    "    \"\"\"\n",
    "      Detalhando mais\n",
    "\n",
    "      cv2.waitKey(10)\n",
    "\n",
    "            cv2.waitKey() é uma função do OpenCV\n",
    "            Que espera por uma entrada de tecla por um certo período de tempo em milissegundos\n",
    "            Passado como argumento. \n",
    "            Nesse caso, 10 indica que o programa espera 10 milissegundos.\n",
    "            Se uma tecla for pressionada durante esse tempo o código da tecla será retornado.\n",
    "            Se nenhum valor for passado, o waitKey() não bloqueia a execução e retorna -1 se nenhuma tecla for pressionada\n",
    "    \n",
    "      & 0xFF\n",
    "\n",
    "            O operador & 0xFF é uma operação de bitwise AND com 0xFF (255 em hexadecimal).\n",
    "            Isso é feito para garantir compatibilidade com sistemas operacionais diferentes.\n",
    "            Isolando o último byte do código da tecla pressionada. \n",
    "            Muitas vezes, sistemas operacionais retornam um valor de 32 bits.\n",
    "            Mas 0xFF restringe o valor à faixa de 0 a 255, que é a faixa da tabela ASCII.    \n",
    "    \n",
    "      == ord('c')\n",
    "\n",
    "           ord('c') retorna o código ASCII do caractere 'c', que é 99.\n",
    "           Esse trecho está verificando se a tecla pressionada foi 'c'. \n",
    "           Se for, a condição do if será verdadeira, permitindo que um bloco de código seja \n",
    "           executado a seguir.\n",
    "    \"\"\"\n",
    "    if cv2.waitKey(10) & 0xFF == ord('c'):\n",
    "        break\n",
    "# agora para fechar a caputura fora do if e do while\n",
    "cap.release()\n",
    "# também, vamos fechar todas as janelas/pop-ups, pois o método imshow() vai abrir um pop-up, mostrando um frame\n",
    "cv2.destroyAllWindows()\n",
    "# agora é só conectar a camera e executar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.14-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting absl-py (from mediapipe)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting attrs>=19.1.0 (from mediapipe)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting flatbuffers>=2.0 (from mediapipe)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.4.35-cp312-cp312-win_amd64.whl.metadata (1.0 kB)\n",
      "Collecting matplotlib (from mediapipe)\n",
      "  Using cached matplotlib-3.9.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\ead\\documents\\artur\\redes_n\\.venv\\lib\\site-packages (from mediapipe) (2.1.2)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
      "  Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Using cached sounddevice-0.5.1-py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe)\n",
      "  Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting ml-dtypes>=0.4.0 (from jax->mediapipe)\n",
      "  Using cached ml_dtypes-0.5.0-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Collecting opt-einsum (from jax->mediapipe)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting scipy>=1.10 (from jax->mediapipe)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->mediapipe)\n",
      "  Using cached contourpy-1.3.0-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->mediapipe)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->mediapipe)\n",
      "  Using cached fonttools-4.54.1-cp312-cp312-win_amd64.whl.metadata (167 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->mediapipe)\n",
      "  Using cached kiwisolver-1.4.7-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ead\\documents\\artur\\redes_n\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Collecting pillow>=8 (from matplotlib->mediapipe)\n",
      "  Using cached pillow-11.0.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->mediapipe)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ead\\documents\\artur\\redes_n\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Collecting pycparser (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ead\\documents\\artur\\redes_n\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Using cached mediapipe-0.10.14-cp312-cp312-win_amd64.whl (50.8 MB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached sounddevice-0.5.1-py3-none-win_amd64.whl (363 kB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached jax-0.4.35-py3-none-any.whl (2.2 MB)\n",
      "Using cached jaxlib-0.4.35-cp312-cp312-win_amd64.whl (56.6 MB)\n",
      "Using cached matplotlib-3.9.2-cp312-cp312-win_amd64.whl (7.8 MB)\n",
      "Using cached opencv_contrib_python-4.10.0.84-cp37-abi3-win_amd64.whl (45.5 MB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Using cached contourpy-1.3.0-cp312-cp312-win_amd64.whl (218 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.54.1-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "Using cached kiwisolver-1.4.7-cp312-cp312-win_amd64.whl (55 kB)\n",
      "Using cached ml_dtypes-0.5.0-cp312-cp312-win_amd64.whl (213 kB)\n",
      "Using cached pillow-11.0.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: flatbuffers, scipy, pyparsing, pycparser, protobuf, pillow, opt-einsum, opencv-contrib-python, ml-dtypes, kiwisolver, fonttools, cycler, contourpy, attrs, absl-py, matplotlib, jaxlib, CFFI, sounddevice, jax, mediapipe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Acesso negado: 'c:\\\\Users\\\\ead\\\\Documents\\\\Artur\\\\Redes_N\\\\.venv\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.VideoCapture 000001E99EAC72F0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.VideoCapture(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Códigos essenciais\n",
    "\n",
    "# while cap.isOpened() - enquanto a camera estiver aberta o while continuara rodando\n",
    "while cap.isOpened():\n",
    "    # vamos criar duas variáveis\n",
    "    \n",
    "    # SUCESSO verifica se os dados estão sendo coletados.\n",
    "            #  Ela é booleana, significa que se identificar algum vídeo ou frame, retornará verdadeiro. Se não identificar nenhum vídeo, retornará falso\n",
    "    # FRAME é uma variável frame que por sua vez, é a captura coletada pela câmera. \n",
    "\n",
    "    sucesso,frame = cap.read()  # Utilizaremos o método cap.read() para leitura\n",
    "    # agora vamos usar o if (condicional), vamos verificar se existe ou não captura acontecendo\n",
    "    # se não tivermos sucesso (booleano), queremos uma mensagem na tela - ignorando o frame vazio da camêra\n",
    "    # essa mensagem é um aviso, logo , nada esta acontecendo no nosso projeto\n",
    "    if not sucesso:\n",
    "        print('Ignorando o frame vazio da camêra')\n",
    "        continue # pesquise sobre a diferença do continue e break (história go to)\n",
    "    # depois disso, saímos do bloco condicional e podemos visualizar a captura e conferir o que está acontecendo.\n",
    "    # podemos contar com o método imshow( ) pra isso\n",
    "    # dentro dos parenteses passamos dois parâmetros 'Camera' e frame\n",
    "    # Passaremos um nome para nossa janela no formato string 'Camera'\n",
    "    # Também outro parametro - frame - definindo que o que queremos mostrar que é nosso próprio frame\n",
    "    cv2.imshow('Camera',frame)\n",
    "    # com isso, conseguiremos mostrar a imagem, mas não temos uma opção de controle para fechar a camera em tempo real.\n",
    "    # Para isso, usaremos um condicional if\n",
    "    # Ele vai pegar o laço de repetição quando apertarmos teclas específicas.\n",
    "    # Como a intenção é fechar vamos usar \"C\" de \"Close\"\n",
    "    # waitKey(10) vai esperar uma chave\n",
    "    # verificar se essa chave é c\n",
    "    # Para isso passamos & OxFF \n",
    "    \"\"\"\n",
    "      Detalhando mais\n",
    "\n",
    "      cv2.waitKey(10)\n",
    "\n",
    "            cv2.waitKey() é uma função do OpenCV\n",
    "            Que espera por uma entrada de tecla por um certo período de tempo em milissegundos\n",
    "            Passado como argumento. \n",
    "            Nesse caso, 10 indica que o programa espera 10 milissegundos.\n",
    "            Se uma tecla for pressionada durante esse tempo o código da tecla será retornado.\n",
    "            Se nenhum valor for passado, o waitKey() não bloqueia a execução e retorna -1 se nenhuma tecla for pressionada\n",
    "    \n",
    "      & 0xFF\n",
    "\n",
    "            O operador & 0xFF é uma operação de bitwise AND com 0xFF (255 em hexadecimal).\n",
    "            Isso é feito para garantir compatibilidade com sistemas operacionais diferentes.\n",
    "            Isolando o último byte do código da tecla pressionada. \n",
    "            Muitas vezes, sistemas operacionais retornam um valor de 32 bits.\n",
    "            Mas 0xFF restringe o valor à faixa de 0 a 255, que é a faixa da tabela ASCII.    \n",
    "    \n",
    "      == ord('c')\n",
    "\n",
    "           ord('c') retorna o código ASCII do caractere 'c', que é 99.\n",
    "           Esse trecho está verificando se a tecla pressionada foi 'c'. \n",
    "           Se for, a condição do if será verdadeira, permitindo que um bloco de código seja \n",
    "           executado a seguir.\n",
    "    \"\"\"\n",
    "    if cv2.waitKey(10) & 0xFF == ord('c'):\n",
    "        break\n",
    "# agora para fechar a caputura fora do if e do while\n",
    "cap.release()\n",
    "# também, vamos fechar todas as janelas/pop-ups, pois o método imshow() vai abrir um pop-up, mostrando um frame\n",
    "cv2.destroyAllWindows()\n",
    "# agora é só conectar a camera e executar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe.solutions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolutions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mface_mesh\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FaceMesh\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe.solutions'"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "from mediapipe.solutions.face_mesh import FaceMesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as facemesh:\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignorando o Frame vaziu da camera\")\n",
    "            continue\n",
    "        frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        saida_facemesh = facemesh.process(frame)\n",
    "        frame = cv2.cvtColor(frame,cv2.COLOR_RGB2BGR)\n",
    "        for face_landmarks in saida_facemesh:\n",
    "            mp_drawing.draw_landmarks(frame, face_landmarks, mp_face_mesh.FACEMESH_CONTOURS)\n",
    "        cv2.imshow(\"Camera\",frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord(\"c\"):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
